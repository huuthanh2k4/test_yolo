import streamlit as st
from streamlit_webrtc import webrtc_streamer, RTCConfiguration
import av
import cv2
import torch # Th√™m th∆∞ vi·ªán torch ƒë·ªÉ ki·ªÉm tra GPU
from ultralytics import YOLO
from PIL import Image
import numpy as np

# 1. C·∫•u h√¨nh WebRTC
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)

# 2. Giao di·ªán Sidebar - Ch·ªçn thi·∫øt b·ªã x·ª≠ l√Ω
st.sidebar.title("C·∫•u h√¨nh h·ªá th·ªëng")

# Ki·ªÉm tra xem m√°y t√≠nh c√≥ GPU (CUDA) kh√¥ng
cuda_available = torch.cuda.is_available()
device_options = ["CPU"]
if cuda_available:
    device_options.append("GPU (CUDA)")
    device_default_index = 1 # ∆Øu ti√™n ch·ªçn GPU n·∫øu c√≥
else:
    device_default_index = 0

device_choice = st.sidebar.radio(
    "Thi·∫øt b·ªã x·ª≠ l√Ω (Inference Device):",
    device_options,
    index=device_default_index,
    help="GPU s·∫Ω cho t·ªëc ƒë·ªô nhanh h∆°n nhi·ªÅu so v·ªõi CPU."
)

# Quy·∫øt ƒë·ªãnh ch·ªçn device cho YOLO
# 'cpu' ho·∫∑c 0 (th∆∞·ªùng l√† GPU ƒë·∫ßu ti√™n)
target_device = 'cpu' if device_choice == "CPU" else 0

# 3. T·∫£i m√¥ h√¨nh YOLO (truy·ªÅn tham s·ªë device v√†o)
@st.cache_resource
def load_model(device):
    model = YOLO('yolov8n.pt') 
    # Chuy·ªÉn model sang thi·∫øt b·ªã ƒë√£ ch·ªçn
    model.to(device)
    return model

model = load_model(target_device)

# Hi·ªÉn th·ªã th√¥ng tin thi·∫øt b·ªã ƒëang d√πng
if target_device == 0:
    st.sidebar.success(f"üöÄ ƒêang s·ª≠ d·ª•ng: {torch.cuda.get_device_name(0)}")
else:
    st.sidebar.info("üê¢ ƒêang s·ª≠ d·ª•ng: CPU")

# --- PH·∫¶N GIAO DI·ªÜN CH√çNH ---
st.markdown("<h1 style='text-align: center;'>üê± AI Cat Detector (CPU/GPU)</h1>", unsafe_allow_html=True)

mode = st.sidebar.selectbox(
    "Ch·∫ø ƒë·ªô s·ª≠ d·ª•ng",
    ["üé• Webcam Th·ªùi gian th·ª±c", "üì∏ Ch·ª•p ·∫£nh & T·∫£i file"]
)

# --- CH·ª®C NƒÇNG 1: WEBCAM TH·ªúI GIAN TH·ª∞C ---
if mode == "üé• Webcam Th·ªùi gian th·ª±c":
    st.subheader("Real-time Detection")

    def video_frame_callback(frame):
        img = frame.to_ndarray(format="bgr24")

        # Ch·∫°y nh·∫≠n di·ªán v·ªõi device ƒë√£ ch·ªçn
        # Ch√∫ng ta d√πng tr·ª±c ti·∫øp target_device ·ªü ƒë√¢y
        results = model.predict(img, conf=0.4, device=target_device, verbose=False)
        
        annotated_frame = results[0].plot()
        return av.VideoFrame.from_ndarray(annotated_frame, format="bgr24")

    webrtc_streamer(
    key="cat-detector",
    rtc_configuration=RTC_CONFIGURATION,
    video_frame_callback=video_frame_callback,
    media_stream_constraints={
        "video": {
            "width": {"ideal": 320, "max": 640}, # Gi·∫£m ƒë·ªô ph√¢n gi·∫£i xu·ªëng 320p cho nh·∫π
            "frameRate": {"ideal": 10, "max": 15}, # Gi·∫£m FPS xu·ªëng ƒë·ªÉ tr√°nh lag
            "facingMode": "environment",
        },
        "audio": False,
    },
    async_processing=True,
)

# --- CH·ª®C NƒÇNG 2: CH·ª§P ·∫¢NH & T·∫¢I FILE ---
else:
    st.subheader("Ch·ª•p ·∫£nh ho·∫∑c T·∫£i file")
    choice = st.radio("Ngu·ªìn ·∫£nh:", ["Camera", "T·∫£i ·∫£nh t·ª´ m√°y"], horizontal=True)
    
    img_input = None
    if choice == "Camera":
        img_input = st.camera_input("Ch·ª•p m·ªôt b·ª©c ·∫£nh")
    else:
        img_input = st.file_uploader("Ch·ªçn ·∫£nh...", type=["jpg", "jpeg", "png"])

    if img_input:
        image = Image.open(img_input)
        img_array = np.array(image)
        
        with st.spinner(f"ƒêang x·ª≠ l√Ω tr√™n {device_choice}..."):
            # Ch·∫°y nh·∫≠n di·ªán
            results = model.predict(img_array, conf=0.4, device=target_device)
            st.image(results[0].plot(), use_container_width=True)
            
            count = len(results[0].boxes)
            st.success(f"Ph√°t hi·ªán {count} ƒë·ªëi t∆∞·ª£ng!")

# 4. CSS T√πy ch·ªânh
st.markdown("""
    <style>
    video { border-radius: 15px; border: 2px solid #ff4b4b; }
    .stSidebar { background-color: #f8f9fa; }
    </style>

    """, unsafe_allow_html=True)
